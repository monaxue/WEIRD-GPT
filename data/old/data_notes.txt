The [task]_history.txt files are the live recording of GPT's answers in the randomized order that the questions were run. If there appears to be errors in the data files, make sure to cross-check with the history files. Note, some of the code for creating the history files were changed between runs, so there may be differences in how the answers were formatted, and earlier version may have missing information. For instance, earlier versions did not record down interations numbers, when and error occured, or the name of the task where the error occured.

The data for the cognitive tasks are in the files cognitive_qs.xlsx and cognitive_qs_num_removed.xlsx. cognitive_qs.xlsx contains GPT's answers including the numers before a numerated list. cognitive_qs_num_removed.xlsx has those number heads removed. Both may have missing or offset answers. This is because while converting GPT's answer to a dataframe, some answers were accidentally removed, or there were extra empty vectors that caused answer to be shifted. When you see missing answers in the excel sheets, or number heads that are offset, or answers in the extra task names towards the right of the excel sheet (names that were not intentionally created in the intial dataframe in [task]_questions.py), be sure to either cross check with either cognitive_qs_num_removed.xlsx or cogntive_history.txt for the actual answers.

The data for the values tasks are in values_qs_[number].xlsx. The different numbers represent separate runs. These dataframes need to be concatanated. There are some missing answers here that are due to answers being cut off during the process of converting GPT responses to a dataframe. You may choose to find these missing answers in values_history.txt. 

In hindsight, I'm realizing that there are ways to code the script such that there wouldn't be as many missing or offset answers. But it's a litle too late to rerun everything with the new code :/